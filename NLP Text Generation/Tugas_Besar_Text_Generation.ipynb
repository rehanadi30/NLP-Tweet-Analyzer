{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tugas Besar - Text Generation.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m-VRgn-qzrP9"
      },
      "source": [
        "\n",
        "\n",
        "**Model Text Generation**\n",
        "\n",
        "PIC: Amanda Eliora"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "S6oH4GFFfqaO",
        "outputId": "c686fdb7-ef9d-4aed-ec58-0ca12eed4b39"
      },
      "source": [
        "%matplotlib inline\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, LSTM, Dense, Embedding, Flatten, TimeDistributed, Dropout, LSTMCell, RNN, Bidirectional, Concatenate, Layer\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.python.keras.utils import tf_utils\n",
        "from tensorflow.keras import backend as K\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "import unicodedata\n",
        "import re\n",
        "import numpy as np\n",
        "import os\n",
        "import time\n",
        "import shutil\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import string, os \n",
        "tf.__version__"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.7.0'"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aUKv1DxBQBjp",
        "outputId": "bdc6194b-fb54-4373-b0d0-3cf1f39c6505"
      },
      "source": [
        "# inisiliasi corpus\n",
        "file = pd.read_csv('Twitter_Emotion_Dataset.csv')\n",
        "corpus = [row for row in file['tweet']]\n",
        "\n",
        "# contoh isi corpus\n",
        "corpus[30:40]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Foto saya di instagram masih ada cuma lupa password instanya jadi ngga bisa di buka !! ini pasti salah pemerintah dan instagram kenapa sampai pakai password segala !! Tuh sampai lupa khan gw #begoloe ',\n",
              " 'Drama kmarin sore : seharian puasa trus pas lg mandi kaget bcz kedatangan tamu tak diundang pas bgt woi pas lagi adzan maghrib trus jd galau dong seharian itu dianggap sah puasa apa enggak-_-',\n",
              " 'Sungguh mencintaimu berat sekali. Berpisah denganmu apalagi. #HadiahPerasaan - [USERNAME] Selalu bikin baper tp sukses melupakan laper. [URL]',\n",
              " '4. pas uda dikirim kembali, si kurir telp ngeluh dan mager buat nganter ke alamat yg bener. malah minta ketemuan di titik yg dia tau itupun dia gamau susah (no puter balik, hrs searah sama arah kendaraan dia jalan)',\n",
              " 'Pada akhirnya kita akan melewati semua ini, semua yang dulu kita bayangkan betapa sulitnya. Kita lalui juga. Di akhir kita hanya bisa belajar, belajar, dan belajar. Memetik semua hikmah yang bisa kita petik. Mempersiapkan untuk kedepan.',\n",
              " 'Kenapa pasangan seringkali diibaratkan sebagai \"rumah\"? Karena rasa nyaman bersamanya senyaman berada di rumah, kamu bisa jadi apa saja, kamu selalu pulang menujunya ',\n",
              " 'Ya tau kalo rasa sakit hati memamg sulit, tapi ada kala nya saat di jenjang rumah tangga jangan lah di publikan situasi saat ini...media itu jahat enggak menyelesaikan masalah dengan terlontarnya kata demi kata',\n",
              " 'Ponakan kls 4 SD: lg demen nonton video tutorial masak + craft @ YouTube. gw kls 4 SD: udah baca novel2 Marga T. &amp Mira W. minjem punya sepupu',\n",
              " 'Bberapa tahun kemudian kesejahteraan keluarga makmak ini teus meningkat. Sampailah suaminya itu dpet pangkat yg tinggi. Kurang paham juga tentang pangkat2an di TNI. Pokonya sudah hidup bekecukupan.',\n",
              " 'Bukan tidak mendukung atau mendoakan, cuma menyikapi apa yang sudah2, itu pilihanmu dan berupayalah mempertahankannya...disini aku dari jauh seharusnya bahagia tapi melihatmu sedih kebahagianku pudar...seperti saat kala itu menerima undangan pernikahanmu.']"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h-oO6BZUCdMS"
      },
      "source": [
        "# Preprocessing data\n",
        "# membuat semua huruf lowercase\n",
        "# usernamd dan url sudah di mask dalam dataset yang dipakai \n",
        "\n",
        "def preprocess(data):\n",
        "  output = []\n",
        "  for line in data:\n",
        "    line.lower()\n",
        "    output.append(line)\n",
        "  return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1hxBDHSk9Vu8"
      },
      "source": [
        "# Tokenisasi\n",
        "\n",
        "tokenizer = Tokenizer()\n",
        "tokenized_corpus = tokenizer.fit_on_texts(corpus)\n",
        "tokenized_corpus = tokenizer.texts_to_sequences(corpus)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jJvI0Ag49-sv",
        "outputId": "a27ec217-770f-4ab3-a05c-be55e6141f3a"
      },
      "source": [
        "# Membagi data menjadi input dan output variables\n",
        "\n",
        "dataX = []\n",
        "dataY = []\n",
        "for line in tokenized_corpus:\n",
        "  token_list = line\n",
        "  for i in range(0, len(token_list)):\n",
        "    seg_in = token_list[:i+1]\n",
        "    seg_out = token_list[i+1:]\n",
        "    dataX.append(seg_in)\n",
        "    dataY.append(seg_out)\n",
        "n_patterns = len (dataX)\n",
        "print(\"Total Patterns: \", n_patterns)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Patterns:  127167\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NHt4zFgw1nLj"
      },
      "source": [
        "# padding data input\n",
        "target_data = tf.keras.preprocessing.sequence.pad_sequences(dataX, padding=\"post\")\n",
        "\n",
        "# reshape X menjadi [samples, time steps, features]\n",
        "target_data = target_data.reshape((target_data.shape[0], target_data.shape[1], 1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U9XvIMxM9Myk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7179a0a0-15db-42c4-8c5c-3cb243c487aa"
      },
      "source": [
        "# parameter model LSTM\n",
        "\n",
        "pd.set_option('display.max_colwidth', -1)\n",
        "BATCH_SIZE = 200\n",
        "embedding_dim = 100\n",
        "units = 200"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: FutureWarning: Passing a negative integer is deprecated in version 1.0 and will not be supported in future version. Instead, use None to not limit the column width.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_sppKQr_8DlB"
      },
      "source": [
        "vocab_size = len(tokenizer.word_index) + 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fn6Hd2NR8LuG",
        "outputId": "d99f391b-54fc-4afb-e7c1-ae70acfa44a2"
      },
      "source": [
        "print(vocab_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "19443\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 273
        },
        "id": "hYAO701mBnka",
        "outputId": "1aa8f67c-2847-44fc-c28c-90a6d98462f6"
      },
      "source": [
        "# Vectorisasi data dengan one-hot encoding\n",
        "\n",
        "seq_length = 100\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "sequences = np.array(sequences)\n",
        "y = to_categorical(np.array(dataY))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return array(a, dtype, copy=False, order=order)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-50-a4b18f75097e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mn_patterns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# one hot encode the output variable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0msequences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_categorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'sequences' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nFi1x4KW8g4r",
        "outputId": "b9ef0883-63b3-4eeb-dcf0-42c710bdad37"
      },
      "source": [
        "# Membangun model LSTM\n",
        "\n",
        "model = keras.Sequential()\n",
        "model.add(Embedding(input_dim=vocab_size, output_dim=embedding_dim))\n",
        "model.add(LSTM(100))\n",
        "model.add(Dense(100, activation='relu'))\n",
        "model.add(Dense(vocab_size, activation='softmax'))\n",
        "model.compile(optimizer='adam', loss=\"sparse_categorical_crossentropy\", metrics=['sparse_categorical_accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_8 (Embedding)     (None, None, 100)         1944300   \n",
            "                                                                 \n",
            " lstm_11 (LSTM)              (None, 100)               80400     \n",
            "                                                                 \n",
            " dense_16 (Dense)            (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_17 (Dense)            (None, 19443)             1963743   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,998,543\n",
            "Trainable params: 3,998,543\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "id": "3rtYr7Q_Assf",
        "outputId": "ea501e68-7b0c-4acc-a4fb-ea32b9bb4ad7"
      },
      "source": [
        "model.fit(dataX, dataY, batch_size=256, epochs=5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return array(a, dtype, copy=False, order=order)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-d2287878debe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m    104\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m   \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Failed to convert a NumPy array to a Tensor (Unsupported object type list)."
          ]
        }
      ]
    }
  ]
}